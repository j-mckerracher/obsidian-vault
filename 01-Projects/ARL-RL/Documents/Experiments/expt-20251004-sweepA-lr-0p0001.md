---
title: "Sweep A Learning Rate 0.0001"
experiment_id: "expt-20251004-sweepA-lr-0p0001"
date: "2025-10-04"
last_updated: "2025-11-30T12:08:00Z"
status: "completed"
tags: ["project/arl-rl", "experiment", "sweep", "learning-rate", "E1"]
dataset: ""
algorithm: "DQN"
params:
  LR: 0.0001
  EPS_DECAY: 50000
  TARGET_UPDATE_FREQ: 100
  RESOLUTION: "32x32" # Inferred from notes
  BATCH_SIZE: 8 # Inferred from notes
  REPLAY_MEMORY_SIZE: 50000 # Inferred from notes
seeds: []
code_ref:
  repo: ""
  commit: ""
  entrypoint: ""
artifacts: "/depot/sbagchi/data/josh/RL/FindAndDefeatZerglings/results_split_advanced//20251004_233022_sweepA_lr_0p0001"
job_ids: []
metrics:
  primary: { name: "win_rate", value: 6.0 }
  others:
    avg_reward: 0.11
hardware: {}
sources: []
related: []
---
## Summary
This experiment was part of Sweep A, investigating the impact of a learning rate of 0.0001.

## Goal
To test the learning rate candidate (LR=0.0001) as part of Sweep A.

## Setup (Hardware/Software)
- **Environment:** Gilbreth (inferred from artifacts path)
- **Resolution:** 32x32
- **Batch Size:** 8
- **Replay Memory Size:** 50,000

## Procedure
Specific procedure details (e.g., job submission commands) are not explicitly recorded in this legacy note.

## Results
- **100-episode test win rate:** 6.0%
- **Average reward:** 0.11

## Analysis
The note provides no explicit analysis beyond the results.

## Issues
Lack of detailed setup information and job commands.

## Next Steps
(Not specified in original note)

## Jobs
- [[01 Projects/ARL-RL/Job-Submission-Commands/2025-10-04-expt-20251004-sweepA-lr-0p0001.md]] â€” status: unknown

## Artifacts
- Path: `/depot/sbagchi/data/josh/RL/FindAndDefeatZerglings/results_split_advanced//20251004_233022_sweepA_lr_0p0001`

## Links

## Changelog
- 2025-11-30T12:08:00Z Created from template, migrated from `20251004_233022_sweepA_lr_0p0001.md`
