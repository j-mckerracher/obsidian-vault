---
title: "Work Log — 2025-10-25"
date: "2025-10-25"
last_updated: "2025-10-25T16:48:50Z"
tags: ["project/arl-rl", "worklog"]
---

# Daily Work Log — 2025-10-25

## Summary
Completed Phase 1 documentation restructuring (5 canonical experiments, standardized Experiments.md, updated Status/Documents). Initiated Phase 2 legacy consolidation. Submitted 64×64 resolution scaling jobs to queue (pending).

## Tasks Done
- ✅ Created Documents/Index.md navigation hub
- ✅ Migrated 5 key experiments to Documents/Experiments/ with full YAML:
  - expt-20251025-e2-prod-3k (94.3% mean, 3k episodes)
  - expt-20251025-e2-confirm-1k (91.3%, 1k episodes)
  - expt-20251025-e2-tuf-sweep (52.7%, 500 episodes)
  - expt-20251025-e3-per-smoke (α=0.6, underperformed)
  - expt-20251025-e3-per-sweep (α∈{0.4,0.5}, parked PER)
- ✅ Standardized Experiments.md with canonical key experiments table
- ✅ Updated Status.md to GREEN with consolidated summary
- ✅ Created RESTRUCTURING_SUMMARY_2025-10-25.md documenting all changes, naming conventions, QA, and Phase 2 plan
- ✅ Committed Phase 1 (git commit 37589f5)
- ✅ Drafted Phase 2 tasks (job notes, daily logs, legacy migration, plan updates)
- ✅ Created Work Completed/2025-10 folder and this daily log entry

## Experiments Touched
- [[expt-20251025-e2-prod-3k]] — E2 production 3k validation
- [[expt-20251025-e2-confirm-1k]] — E2 confirmation 1k runs
- [[expt-20251025-e2-tuf-sweep]] — E2 gate validation 500 eps
- [[expt-20251025-e3-per-smoke]] — E3 PER smoke (α=0.6)
- [[expt-20251025-e3-per-sweep]] — E3 PER alpha sweep
- All migrated to Documents/Experiments/ from old Experiments/ location

## Commands Run
- Documentation only; no research/training runs executed today
- Prepared for resolution scaling (64×64) runs queued on Gilbreth

## Time Spent
- Documentation restructuring: ~2 hours
- Phase 1 completion and commit: ~30 minutes
- Phase 2 planning: ~15 minutes

## Next Day Plan (2025-10-26)

### High Priority
1. Monitor 64×64 resolution scaling jobs (E2 config at higher resolution)
   - Expected results in Work Completed/2025-10/2025-10-26.md
   - Job IDs: (to be recorded when jobs start)
2. Continue Phase 2 legacy consolidation:
   - Create Job-Submission-Commands notes for E2/E3 key runs
   - Batch-migrate 23 legacy E1/early-E2 experiments to Documents/Experiments/
3. Update Plan.md with milestones/tasks/risks using Plan.template.md

### Medium Priority
- Cross-link audit and final validation
- Create daily log for 2025-10-26 once resolution scaling results arrive
- Document 64×64 results in canonical experiment note (expt-20251025-e2-res64)

### Optional
- Set up Obsidian dataview queries for experiment filtering
- Create KPI dashboard queries

## Links
- [[../../../Experiments]] — Updated hub
- [[../../../Status]] — Updated status
- [[../../../Documents/Index]] — New navigation hub
- [[../../../RESTRUCTURING_SUMMARY_2025-10-25]] — Full Phase 1 details

## Changelog
- 2025-10-25T16:48:50Z Created daily work log for Phase 1 completion and Phase 2 initiation

---

## E2 Dueling DQN Validation & Config Freeze

### Summary
Successfully validated Stage E2 (Dueling DQN) through TUF-sweep-alt-3 (500 episodes) and 1k-episode confirmatory runs (run-6). E2 configuration achieved 91.3% mean win rate with 4.0 pp stdev across seeds 4, 6, and 8. Configuration frozen for production use.

### Work completed

#### TUF-sweep-alt-3 (500 episodes, gate validation)
- **Objective**: Validate dueling DQN with TUF=400 and E2 baseline hyperparameters
- **Configuration**: Dueling DQN enabled, TUF=400, LR=5e-5, EPS_DECAY=100k, Batch=4, Replay=100k, Res=32, StepMul=16
- **Seeds**: 4, 6, 8
- **Results**: 
  - Seed 4: 56.0%
  - Seed 6: 68.0%
  - Seed 8: 34.0%
  - Mean: 52.7%, StdDev: 35.9 pp
- **Gate criterion**: PASSED (mean ≥ 44%, stdev < 40 pp)
- **Artifacts**: `/depot/sbagchi/data/josh/RL/FindAndDefeatZerglings/results_split_advanced/TUF-sweep-alt-3/`

#### run-6 (1,000-episode confirmatory runs)
- **Objective**: Confirm E2 performance at 1k episodes per seed
- **Configuration**: Same as TUF-sweep-alt-3 with NUM_EPISODES=1000
- **Seeds**: 4, 6, 8
- **Results**:
  - Seed 4: 92.0%
  - Seed 6: 95.0%
  - Seed 8: 87.0%
  - Mean: 91.3%, StdDev: 4.0 pp
- **Outcome**: **E2 CONFIRMED** — Outstanding performance and stability
- **Artifacts**: `/depot/sbagchi/data/josh/RL/FindAndDefeatZerglings/results_split_advanced/run-6/`

#### Configuration freeze
- **Decision**: Freeze E2 configuration as production baseline
- **Documentation**: Created [[E2 Config Freeze]]
- **Frozen parameters**:
  - DUELING_DQN: enabled
  - LR: 5e-5
  - EPS_DECAY: 100000
  - TARGET_UPDATE_FREQ: 400
  - BATCH_SIZE: 4
  - REPLAY_MEMORY_SIZE: 100000
  - SCREEN_RESOLUTION: 32
  - STEP_MUL: 16

### Impact
- E2 baseline vastly outperforms E1 (44.0% → 91.3% mean win rate)
- Low variance (4.0 pp stdev) indicates stable, reproducible training
- All three seeds performed strongly (87-95% range)
- Configuration ready for long-duration production runs

### Experiment logs
- [[20251025_E2_TUF_sweep_alt3]]
- [[20251025_E2_run6_confirm_1k]]

---

## E2 Production 3k Validation Complete

### Summary
Successfully completed Stage E2 production validation with 3,000-episode runs across seeds 4, 6, and 8. Achieved **94.3% mean win rate** (97%/88%/98%), exceeding 1k-episode results (91.3%) and confirming E2 configuration as production-ready at scale.

### Work completed

#### E2 production runs (3,000 episodes per seed)
- **Configuration**: Frozen E2 baseline (Dueling DQN, TUF=400, LR=5e-5, EPS_DECAY=100k, Batch=4, Replay=100k, Res=32, StepMul=16)
- **Seeds**: 4, 6, 8
- **Episodes**: 3,000 per seed
- **Results**:
  - Seed 4: **97.0%** win rate (502.0 total reward, 5.02 avg)
  - Seed 6: **88.0%** win rate (163.0 total reward, 1.63 avg)
  - Seed 8: **98.0%** win rate (517.0 total reward, 5.17 avg)
  - **Mean: 94.3%, StdDev: 5.7 pp**
- **Artifacts (HPC)**: `/depot/sbagchi/data/josh/RL/FindAndDefeatZerglings/results_split_advanced/20251025_021201_E1_seed{4,6,8}/`
- **Artifacts (local)**: `C:\Users\jmckerra\OneDrive - purdue.edu\Documents\ARL-RL-Experiment-Results\10-25-2025\`

#### Performance progression confirmed
- 500 episodes: 52.7% mean (TUF-sweep-alt-3)
- 1,000 episodes: 91.3% mean (run-6 confirmatory)
- 3,000 episodes: **94.3% mean** (production)
- **Trend**: Robust improvement with scale, stable training

#### Checkpoints saved
- 30+ checkpoints per seed (every 100 episodes)
- File size: ~64MB per checkpoint
- Total: ~6GB across all seeds
- **Recommendation**: Archive strategic checkpoints (ep100, ep1000, ep2000, ep3000), delete intermediates

### Impact
- **E2 validated at scale**: Production-level performance confirmed
- **Best individual result**: Seed 8 achieved 98% win rate (highest yet)
- **Configuration stability**: All seeds performed excellently (88-98% range)
- **Ready for next stage**: Foundation solid for resolution scaling, E4, or deployment

### Commands used
```bash
sbatch --account=sbagchi --partition=a30 --qos=normal --gres=gpu:1 \
  --ntasks=1 --cpus-per-task=4 --mem=50G --time=06:00:00 \
  --export=ALL,RL_SEED=<seed>,RL_NUM_EPISODES=3000,RL_LEARNING_RATE=0.00005,\ 
RL_EPS_DECAY=100000,RL_BATCH_SIZE=4,RL_REPLAY_MEMORY_SIZE=100000,\
RL_SCREEN_RESOLUTION=32,RL_STEP_MUL=16,RL_TARGET_UPDATE_FREQ=400,\ 
RL_DUELING_DQN=1 \
  scripts/run_e2.sh
```

### Next options
1. **Resolution scaling (64×64)**: Test E2 at higher resolution for improved spatial awareness
2. **Stage E4 (N-step returns)**: Add multi-step bootstrapping (n=3) for better credit assignment
3. **Extended validation (4k-5k eps)**: Push convergence limits
4. **Deployment prep**: Prepare best model (seed 8 ep3000) for production/demos

### Experiment log
- [[20251025_E2_production_3k]]

---

## E3 PER Exploration & Parking Decision

### Summary
Completed Stage E3 (Prioritized Experience Replay) exploration through smoke runs and alpha sweep. PER consistently underperformed E2 baseline across all tested configurations (α∈{0.4, 0.5, 0.6}, β annealing). **Decision: Park PER** and proceed with E2 production runs.

### Work completed

#### E3 PER smoke runs (α=0.6, β=0.4→1.0)
- **Objective**: Initial validation of PER with baseline alpha/beta values
- **Configuration**: E2 frozen config + PER enabled (α=0.6, β=0.4→1.0)
- **Seeds**: 4, 6, 8
- **Episodes**: 500 per seed
- **Results**:
  - Seed 4: ~60-70% (decent but below E2)
  - Seed 6: ~50-60% (decent but below E2)
  - Seed 8: ~10-15% (severe instability)
  - Aggregate mean: Well below E2 baseline (91.3%)
- **Observation**: Seed 8 showed severe instability with PER enabled
- **Artifacts**: `/depot/sbagchi/data/josh/RL/FindAndDefeatZerglings/results_split_advanced/E3-smoke/`

#### E3 PER alpha sweep (run-2: α∈{0.4, 0.5}, β=0.6→1.0)
- **Objective**: Find stable alpha configuration by testing lower values
- **Configuration**: E2 frozen config + PER with swept alpha values
- **Seeds**: 4, 6, 8
- **Episodes**: 300-500 per seed
- **Alpha values tested**: 0.4, 0.5
- **Beta annealing**: Adjusted to 0.6→1.0 (from 0.4→1.0 in smoke)
- **Results**:
  - Alpha 0.4: Mean below E2 baseline; seed 8 still unstable
  - Alpha 0.5: Mean below E2 baseline; high variance persists
  - No alpha value matched or exceeded E2 baseline
  - Seed 8 consistently problematic across all PER configurations
- **Artifacts**: `/depot/sbagchi/data/josh/RL/FindAndDefeatZerglings/results_split_advanced/run-2/`

### Decision: Park PER
- **Rationale**: 
  - PER underperforms E2 baseline across all tested configurations
  - High-priority sampling destabilizes training
  - Seed 8 consistently unstable with PER
  - E2 without PER already achieves excellent performance (91.3%)
- **Documentation**: Created [[2025-10-25 Park Stage E3 PER]]
- **Next step**: E2 production runs (2k-4k episodes per seed)

### Commands used

#### Smoke runs (α=0.6)
```bash
sbatch --account=sbagchi --partition=a30 --qos=standby --gres=gpu:1 \
  --ntasks=1 --cpus-per-task=4 --mem=50G --time=02:00:00 \
  --export=ALL,RL_SEED=<seed>,RL_NUM_EPISODES=500,RL_LEARNING_RATE=0.00005,\ 
RL_EPS_DECAY=100000,RL_BATCH_SIZE=4,RL_REPLAY_MEMORY_SIZE=100000,\ 
RL_SCREEN_RESOLUTION=32,RL_STEP_MUL=16,RL_TARGET_UPDATE_FREQ=400,\ 
RL_DUELING_DQN=1,RL_PER_ENABLED=1,RL_PER_ALPHA=0.6,RL_PER_BETA_START=0.4,\ 
RL_PER_BETA_END=1.0 \
  scripts/run_e3.sh
```

#### Alpha sweep (α=0.4, 0.5)
```bash
# Alpha 0.4
sbatch ... RL_PER_ALPHA=0.4,RL_PER_BETA_START=0.6 ...

# Alpha 0.5
sbatch ... RL_PER_ALPHA=0.5,RL_PER_BETA_START=0.6 ...
```

### Impact
- Comprehensive PER exploration completed
- Decision made based on solid empirical evidence
- Resources can now focus on E2 production validation
- PER revisit criteria documented for future consideration

### Observations & lessons learned
- PER may be incompatible with current task/architecture at 32×32 resolution
- High-priority sampling can destabilize learning in sparse reward environments
- Not all algorithmic improvements from literature generalize to all tasks
- Sometimes simpler approaches (E2 without PER) outperform more complex ones

### Future considerations
Revisit PER if:
- Resolution scales to 64×64 or higher
- Architecture changes significantly
- Task complexity increases
- Sample efficiency becomes critical bottleneck

### Experiment logs
- [[20251025_E3_PER_smoke]]
- [[20251025_E3_PER_run2_alpha_sweep]]

---
